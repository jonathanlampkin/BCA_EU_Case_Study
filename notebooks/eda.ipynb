{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abdad87",
   "metadata": {},
   "source": [
    "# 🚗 Car Price Prediction - Comprehensive EDA\n",
    "\n",
    "## Overview\n",
    "This notebook provides a comprehensive Exploratory Data Analysis (EDA) for the EU Car Pricing dataset. We'll analyze data quality, distributions, relationships, and prepare insights for the machine learning pipeline.\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: EUDS_CaseStudy_Pricing.csv\n",
    "- **Target Variable**: targetPrice (car price in euros)\n",
    "- **Features**: 18 features including car specifications, grades, and metadata\n",
    "- **Size**: ~18,575 records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8866b8",
   "metadata": {},
   "source": [
    "## 📦 Package Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -Uq pip\n",
    "%pip install -Uq numpy scipy seaborn matplotlib pandas pyarrow plotly scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7085b0",
   "metadata": {},
   "source": [
    "## 📚 Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316922b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adfa84",
   "metadata": {},
   "source": [
    "## 📊 Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5bc9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Dataset loaded successfully!\n",
      "Shape: (18575, 19)\n",
      "Memory usage: 12.04 MB\n",
      "Columns: ['vehicleID', 'registrationDate', 'kilometers', 'colour', 'aestheticGrade', 'mechanicalGrade', 'saleDate', 'make', 'model', 'doorNumber', 'type', 'fuel', 'transmission', 'yearIntroduced', 'cylinder', 'cubeCapacity', 'powerKW', 'powerHP', 'targetPrice']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/EUDS_CaseStudy_Pricing.csv')\n",
    "\n",
    "print(\"📈 Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe97fd",
   "metadata": {},
   "source": [
    "## 🔍 Basic Data Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n=== FIRST FEW ROWS ===\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e82e31",
   "metadata": {},
   "source": [
    "## 📋 Missing Values Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46662228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_data = df.isnull().sum()\n",
    "missing_pct = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"=== MISSING VALUES SUMMARY ===\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_data.sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df[missing_df['Missing Count'] > 0].plot(kind='bar', y='Missing Count')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Missing Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('artifacts/missing_values_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('artifacts/missing_values_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✅ No missing values found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d54c94",
   "metadata": {},
   "source": [
    "## 🎯 Target Variable Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "target = 'targetPrice'\n",
    "\n",
    "print(\"=== TARGET VARIABLE STATISTICS ===\")\n",
    "print(f\"Mean: €{df[target].mean():,.2f}\")\n",
    "print(f\"Median: €{df[target].median():,.2f}\")\n",
    "print(f\"Std: €{df[target].std():,.2f}\")\n",
    "print(f\"Min: €{df[target].min():,.2f}\")\n",
    "print(f\"Max: €{df[target].max():,.2f}\")\n",
    "print(f\"Skewness: {df[target].skew():.3f}\")\n",
    "print(f\"Kurtosis: {df[target].kurtosis():.3f}\")\n",
    "\n",
    "# Create comprehensive target variable visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(df[target], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Target Price Distribution (Histogram)')\n",
    "axes[0, 0].set_xlabel('Price (€)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[0, 1].boxplot(df[target], patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "axes[0, 1].set_title('Target Price Distribution (Box Plot)')\n",
    "axes[0, 1].set_ylabel('Price (€)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Log-transformed histogram\n",
    "log_target = np.log1p(df[target])\n",
    "axes[1, 0].hist(log_target, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1, 0].set_title('Log-Transformed Target Price Distribution')\n",
    "axes[1, 0].set_xlabel('Log(Price + 1)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "from scipy import stats\n",
    "stats.probplot(df[target], dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot: Target Price vs Normal Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/target_variable_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Price ranges analysis\n",
    "print(\"\\n=== PRICE RANGES ANALYSIS ===\")\n",
    "price_ranges = pd.cut(df[target], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "print(price_ranges.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d476b",
   "metadata": {},
   "source": [
    "## 📊 Numeric Features Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns: {numeric_cols}\")\n",
    "\n",
    "# Basic statistics for numeric columns\n",
    "print(\"\\n=== NUMERIC FEATURES SUMMARY ===\")\n",
    "numeric_summary = df[numeric_cols].describe()\n",
    "print(numeric_summary)\n",
    "\n",
    "# Create distribution plots for all numeric features\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    if i < len(axes):\n",
    "        # Histogram\n",
    "        axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = f'Mean: {df[col].mean():.2f}\\nStd: {df[col].std():.2f}\\nSkew: {df[col].skew():.2f}'\n",
    "        axes[i].text(0.7, 0.8, stats_text, transform=axes[i].transAxes, \n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(numeric_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/numeric_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c1914",
   "metadata": {},
   "source": [
    "## 📦 Box Plots for Numeric Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ce2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for numeric features to identify outliers\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    if i < len(axes):\n",
    "        # Box plot\n",
    "        box_plot = axes[i].boxplot(df[col].dropna(), patch_artist=True)\n",
    "        box_plot['boxes'][0].set_facecolor('lightcoral')\n",
    "        axes[i].set_title(f'{col} Box Plot')\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add outlier count\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)][col]\n",
    "        axes[i].text(0.7, 0.8, f'Outliers: {len(outliers)}', \n",
    "                    transform=axes[i].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(numeric_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/numeric_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaae33b",
   "metadata": {},
   "source": [
    "## 🔗 Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find high correlations\n",
    "print(\"=== HIGH CORRELATIONS (>0.7) ===\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_val))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for col1, col2, corr in high_corr_pairs:\n",
    "        print(f\"{col1} - {col2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No high correlations found (>0.7)\")\n",
    "\n",
    "# Target variable correlations\n",
    "print(\"\\n=== TARGET VARIABLE CORRELATIONS ===\")\n",
    "target_correlations = correlation_matrix[target].drop(target).sort_values(key=abs, ascending=False)\n",
    "print(target_correlations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf294314",
   "metadata": {},
   "source": [
    "## 📊 Categorical Features Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b558c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Analyze each categorical feature\n",
    "print(\"\\n=== CATEGORICAL FEATURES SUMMARY ===\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Most common values:\")\n",
    "    print(df[col].value_counts().head(5))\n",
    "\n",
    "# Create visualizations for categorical features\n",
    "n_cols = 2\n",
    "n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    if i < len(axes):\n",
    "        # Bar plot for top 10 values\n",
    "        value_counts = df[col].value_counts().head(10)\n",
    "        value_counts.plot(kind='bar', ax=axes[i], color='lightgreen')\n",
    "        axes[i].set_title(f'{col} Value Counts (Top 10)')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(categorical_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd16cb2",
   "metadata": {},
   "source": [
    "## 🎯 Target vs Features Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a944b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between target and key features\n",
    "key_features = ['kilometers', 'doorNumber', 'yearIntroduced', 'powerKW', 'powerHP']\n",
    "key_features = [col for col in key_features if col in df.columns]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = (len(key_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(key_features):\n",
    "    if i < len(axes):\n",
    "        # Scatter plot\n",
    "        axes[i].scatter(df[col], df[target], alpha=0.5, s=1)\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Target Price (€)')\n",
    "        axes[i].set_title(f'Target Price vs {col}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add correlation coefficient\n",
    "        corr = df[col].corr(df[target])\n",
    "        axes[i].text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                    transform=axes[i].transAxes,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(key_features), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/target_vs_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c81ea5",
   "metadata": {},
   "source": [
    "## 📊 Categorical Features vs Target Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features vs target\n",
    "categorical_target_cols = ['colour', 'aestheticGrade', 'mechanicalGrade', 'type', 'fuel', 'transmission']\n",
    "categorical_target_cols = [col for col in categorical_target_cols if col in df.columns]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = (len(categorical_target_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(categorical_target_cols):\n",
    "    if i < len(axes):\n",
    "        # Box plot for each category\n",
    "        df.boxplot(column=target, by=col, ax=axes[i])\n",
    "        axes[i].set_title(f'Target Price by {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Target Price (€)')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(categorical_target_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/categorical_vs_target.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751c3cf",
   "metadata": {},
   "source": [
    "## 📋 Summary and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=== EDA SUMMARY AND RECOMMENDATIONS ===\")\n",
    "print(f\"\\n📊 Dataset Overview:\")\n",
    "print(f\"  • Total records: {df.shape[0]:,}\")\n",
    "print(f\"  • Total features: {df.shape[1]}\")\n",
    "print(f\"  • Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"  • Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\n🎯 Target Variable (targetPrice):\")\n",
    "print(f\"  • Mean: €{df[target].mean():,.2f}\")\n",
    "print(f\"  • Median: €{df[target].median():,.2f}\")\n",
    "print(f\"  • Range: €{df[target].min():,.2f} - €{df[target].max():,.2f}\")\n",
    "print(f\"  • Skewness: {df[target].skew():.3f} (right-skewed)\")\n",
    "\n",
    "print(f\"\\n🔍 Data Quality Issues:\")\n",
    "if missing_data.sum() > 0:\n",
    "    print(f\"  • Missing values in: {missing_data[missing_data > 0].index.tolist()}\")\n",
    "else:\n",
    "    print(f\"  • No missing values found\")\n",
    "\n",
    "print(f\"\\n📈 Key Insights:\")\n",
    "if 'powerKW' in df.columns and 'powerHP' in df.columns:\n",
    "    print(f\"  • High correlation between powerKW and powerHP: {df['powerKW'].corr(df['powerHP']):.3f}\")\n",
    "print(f\"  • Strongest predictors of price: {target_correlations.head(3).index.tolist()}\")\n",
    "if 'type' in df.columns:\n",
    "    print(f\"  • Most common car type: {df['type'].mode().iloc[0]}\")\n",
    "if 'fuel' in df.columns:\n",
    "    print(f\"  • Most common fuel type: {df['fuel'].mode().iloc[0]}\")\n",
    "\n",
    "print(f\"\\n🛠️ Preprocessing Recommendations:\")\n",
    "print(f\"  • Handle missing values in colour column\")\n",
    "print(f\"  • Consider log transformation for target variable (right-skewed)\")\n",
    "print(f\"  • Remove or transform outliers in kilometers, powerKW, powerHP\")\n",
    "if 'powerKW' in df.columns and 'powerHP' in df.columns:\n",
    "    print(f\"  • Drop one of powerKW/powerHP due to high correlation\")\n",
    "print(f\"  • Encode categorical variables (colour, aestheticGrade, mechanicalGrade, etc.)\")\n",
    "print(f\"  • Create derived features: car_age_years, km_per_year\")\n",
    "\n",
    "print(f\"\\n📊 Model Recommendations:\")\n",
    "print(f\"  • Use tree-based models (Random Forest, XGBoost, LightGBM) for high cardinality features\")\n",
    "print(f\"  • Consider ensemble methods for better performance\")\n",
    "print(f\"  • Use time series cross-validation due to temporal nature of data\")\n",
    "print(f\"  • Apply feature selection to reduce multicollinearity\")\n",
    "\n",
    "print(f\"\\n✅ EDA Complete! All visualizations saved to 'artifacts/' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6888189",
   "metadata": {},
   "source": [
    "## 🔍 YData Profiling - Original Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ydata-profiling if not already installed\n",
    "%pip install -Uq ydata-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ydata-profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "\n",
    "# Create artifacts directory if it doesn't exist\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "print(\"🔍 Generating YData Profiling report for original data...\")\n",
    "print(\"This may take a few minutes for large datasets...\")\n",
    "\n",
    "# Generate comprehensive profiling report for original data\n",
    "report_original = ProfileReport(\n",
    "    df, \n",
    "    title=\"🚗 Car Pricing Dataset - Original Data EDA\", \n",
    "    explorative=True,\n",
    "    minimal=False,\n",
    "    correlations={\n",
    "        \"pearson\": {\"calculate\": True},\n",
    "        \"spearman\": {\"calculate\": True},\n",
    "        \"kendall\": {\"calculate\": True},\n",
    "        \"phi_k\": {\"calculate\": True},\n",
    "        \"cramers\": {\"calculate\": True}\n",
    "    },\n",
    "    interactions={\n",
    "        \"continuous\": True,\n",
    "        \"targets\": [\"targetPrice\"]\n",
    "    },\n",
    "    missing_diagrams={\n",
    "        \"matrix\": True,\n",
    "        \"bar\": True,\n",
    "        \"heatmap\": True,\n",
    "        \"dendrogram\": True\n",
    "    },\n",
    "    duplicates={\n",
    "        \"head\": 10\n",
    "    },\n",
    "    samples={\n",
    "        \"head\": 5,\n",
    "        \"tail\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save HTML report\n",
    "html_path_original = \"artifacts/eda_report_original.html\"\n",
    "report_original.to_file(html_path_original)\n",
    "\n",
    "# Save JSON report\n",
    "json_path_original = \"artifacts/eda_report_original.json\"\n",
    "with open(json_path_original, \"w\") as f:\n",
    "    f.write(report_original.to_json())\n",
    "\n",
    "print(f\"✅ Original data profiling complete!\")\n",
    "print(f\"📄 HTML report saved: {html_path_original}\")\n",
    "print(f\"📄 JSON report saved: {json_path_original}\")\n",
    "print(f\"🌐 Open the HTML file in your browser to view the interactive report\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee4ca3",
   "metadata": {},
   "source": [
    "## 🔍 YData Profiling - Cleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data if it exists\n",
    "try:\n",
    "    df_clean = pd.read_csv('../artifacts/clean_data.csv')\n",
    "    \n",
    "    print(\"🔍 Generating YData Profiling report for cleaned data...\")\n",
    "    print(\"This may take a few minutes for large datasets...\")\n",
    "    \n",
    "    # Generate comprehensive profiling report for cleaned data\n",
    "    report_clean = ProfileReport(\n",
    "        df_clean, \n",
    "        title=\"🚗 Car Pricing Dataset - Cleaned Data EDA\", \n",
    "        explorative=True,\n",
    "        minimal=False,\n",
    "        correlations={\n",
    "            \"pearson\": {\"calculate\": True},\n",
    "            \"spearman\": {\"calculate\": True},\n",
    "            \"kendall\": {\"calculate\": True},\n",
    "            \"phi_k\": {\"calculate\": True},\n",
    "            \"cramers\": {\"calculate\": True}\n",
    "        },\n",
    "        interactions={\n",
    "            \"continuous\": True,\n",
    "            \"targets\": [\"targetPrice\"]\n",
    "        },\n",
    "        missing_diagrams={\n",
    "            \"matrix\": True,\n",
    "            \"bar\": True,\n",
    "            \"heatmap\": True,\n",
    "            \"dendrogram\": True\n",
    "        },\n",
    "        duplicates={\n",
    "            \"head\": 10\n",
    "        },\n",
    "        samples={\n",
    "            \"head\": 5,\n",
    "            \"tail\": 5\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Save HTML report\n",
    "    html_path_clean = \"artifacts/eda_report_clean.html\"\n",
    "    report_clean.to_file(html_path_clean)\n",
    "    \n",
    "    # Save JSON report\n",
    "    json_path_clean = \"artifacts/eda_report_clean.json\"\n",
    "    with open(json_path_clean, \"w\") as f:\n",
    "        f.write(report_clean.to_json())\n",
    "    \n",
    "    print(f\"✅ Cleaned data profiling complete!\")\n",
    "    print(f\"📄 HTML report saved: {html_path_clean}\")\n",
    "    print(f\"📄 JSON report saved: {json_path_clean}\")\n",
    "    print(f\"🌐 Open the HTML file in your browser to view the interactive report\")\n",
    "    \n",
    "    # Compare original vs cleaned data\n",
    "    print(f\"\\n📊 Data Comparison:\")\n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "    print(f\"Cleaned data shape: {df_clean.shape}\")\n",
    "    print(f\"Rows removed: {df.shape[0] - df_clean.shape[0]}\")\n",
    "    print(f\"Columns added: {df_clean.shape[1] - df.shape[1]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Cleaned data not found. Run 'make preprocess' first to generate clean_data.csv\")\n",
    "    print(\"Skipping cleaned data profiling...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69ca7",
   "metadata": {},
   "source": [
    "## 📊 YData Profiling Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc343fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display YData Profiling reports summary\n",
    "print(\"=== YDATA PROFILING REPORTS GENERATED ===\")\n",
    "print(\"\\n📄 Available Reports:\")\n",
    "print(\"1. Original Data EDA Report:\")\n",
    "print(f\"   • HTML: artifacts/eda_report_original.html\")\n",
    "print(f\"   • JSON: artifacts/eda_report_original.json\")\n",
    "print(\"\\n2. Cleaned Data EDA Report:\")\n",
    "print(f\"   • HTML: artifacts/eda_report_clean.html\")\n",
    "print(f\"   • JSON: artifacts/eda_report_clean.json\")\n",
    "\n",
    "print(\"\\n🔍 What's included in YData Profiling reports:\")\n",
    "print(\"• Dataset overview and statistics\")\n",
    "print(\"• Variable types and data quality\")\n",
    "print(\"• Missing values analysis with visualizations\")\n",
    "print(\"• Duplicate rows detection\")\n",
    "print(\"• Correlation analysis (Pearson, Spearman, Kendall, Phi-K, Cramers)\")\n",
    "print(\"• Interaction plots for continuous variables\")\n",
    "print(\"• Sample data (head and tail)\")\n",
    "print(\"• Alerts for data quality issues\")\n",
    "print(\"• Distribution plots for all variables\")\n",
    "print(\"• Target variable analysis\")\n",
    "\n",
    "print(\"\\n🌐 To view the reports:\")\n",
    "print(\"1. Open the HTML files in your web browser\")\n",
    "print(\"2. Navigate through the interactive sections\")\n",
    "print(\"3. Use the JSON files for programmatic access to the data\")\n",
    "\n",
    "print(\"\\n💡 Pro tip: The YData Profiling reports provide:\")\n",
    "print(\"• Automated data quality assessment\")\n",
    "print(\"• Statistical summaries for all variables\")\n",
    "print(\"• Interactive visualizations\")\n",
    "print(\"• Data quality alerts and recommendations\")\n",
    "print(\"• Professional presentation-ready reports\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130bab4",
   "metadata": {},
   "source": [
    "# 🚗 Car Price Prediction - Comprehensive EDA\n",
    "\n",
    "## Overview\n",
    "This notebook provides a comprehensive Exploratory Data Analysis (EDA) for the EU Car Pricing dataset. We'll analyze data quality, distributions, relationships, and prepare insights for the machine learning pipeline.\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: EUDS_CaseStudy_Pricing.csv\n",
    "- **Target Variable**: targetPrice (car price in euros)\n",
    "- **Features**: 18 features including car specifications, grades, and metadata\n",
    "- **Size**: ~18,575 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e52a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## 📦 Package Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ef028",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "%pip install -Uq pip\n",
    "%pip install -Uq numpy scipy seaborn matplotlib pandas pyarrow plotly scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac467ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 📚 Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4ca3e",
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d040f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## 📊 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98cecf",
   "metadata": {},
   "source": [
    "Quick EDA using Pandas (ydata) Profiling\n",
    "**Overview**\n",
    "**1.** The data is already quite clean with < 0.1% missing cells and 0 duplicate rows.\n",
    "**2.** The data is small and can fit in RAM, we will avoid dropping rows due to a small n.\n",
    "**3.** The data has a healthy mix of data types.\n",
    "**4.** vehicleID is the primary key with all unique values.\n",
    "\n",
    "**Alerts**\n",
    "**1.** There are 9 alerts for High correlation, meaning that we will have to be careful of multicollinearity.\n",
    "**2.** There are a couple of Imbalanced features, meaning that underrepresentation can exist in the data sample.\n",
    "\n",
    "\n",
    "**Columns**\n",
    "**registrationDate:** Proxy for car age, normally distributed and centered around ~2011, meaning that the average age of the cars sold are ~14 years (Assuming that the cars are registered around the same time that they are built).\n",
    "**kilometers:** Heavily right skewed with at least one extreme outlier. The outlier(s) will be removed and the feature will be log transformed to make it more gaussian shaped.\n",
    "**colour:** Modestly high cardinality, we will use model-based feature importance methods later on to derive it's importance (how much variance it explains in the target feature) and decide whether to keep it or not.\n",
    "**aestheticGrade:** Low cardinality and likely a modest predictor for the target variable.\n",
    "**mechanicalGrade:** Low cardinality and likely a modest predictor for the target variable.\n",
    "**saleDate:** Has the correct datatype, useful as an index for the dataset. Need to remove outliers.\n",
    "**make:** High cardinality which is okay for tree-based models but may be problematic for linear models.\n",
    "**model:** High cardinality which is okay for tree-based models but will be problematic for linear models. We may need to bin this feature or exclude it.\n",
    "**doorNumber:** Low cardinality, fine as is.\n",
    "**type:** Low cardinality, fine as is.\n",
    "**fuel:** Low cardinality with an underrepresentation for Electric vehicles.\n",
    "**transmission:** Binary feature we can map to 1/0; Automatic cars are underrepresented and downsampling is an option if n were larger.\n",
    "**yearIntroduced:** May have a high correlation with derived car age from registrationDate.\n",
    "**cylinder:** Need to clip the outlier(s) and impute nulls or drop them.\n",
    "**cubeCapacity:** Will treat 0's as nulls and impute using the median.\n",
    "**powerKW:** Likely perfect collinearity with powerHP, will drop one.\n",
    "**powerHP:** Likely perfect collinearity with powerKW, will drop one.\n",
    "**targetPrice:** Will predict the log of the target and try quantile predictors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03aa34b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33martifacts\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m report = ProfileReport(\u001b[43mdf\u001b[49m, title=\u001b[33m\"\u001b[39m\u001b[33mEDA – Car Pricing\u001b[39m\u001b[33m\"\u001b[39m, explorative=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# HTML\u001b[39;00m\n\u001b[32m      9\u001b[39m html_path = \u001b[33m\"\u001b[39m\u001b[33martifacts/eda_report.html\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "report = ProfileReport(df, title=\"EDA – Car Pricing\", explorative=True)\n",
    "\n",
    "# HTML\n",
    "html_path = \"artifacts/eda_report.html\"\n",
    "report.to_file(html_path)\n",
    "\n",
    "# JSON (best-supported path)\n",
    "json_path = \"artifacts/eda_report.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    f.write(report.to_json())\n",
    "\n",
    "print(f\"Saved: {html_path}\\nSaved: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f36a0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ProfileReport(\u001b[43mdf\u001b[49m, title=\u001b[33m\"\u001b[39m\u001b[33mEDA – Car Pricing\u001b[39m\u001b[33m\"\u001b[39m, explorative=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "ProfileReport(df, title=\"EDA – Car Pricing\", explorative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee7923",
   "metadata": {},
   "source": [
    "Oldschool (Manual) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e37326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df.info()\n",
    "# df.describe()\n",
    "# df.isnull().sum()\n",
    "# df.duplicated().sum()\n",
    "# df.shape\n",
    "# df.corr()\n",
    "# df.skew()\n",
    "# df.kurtosis()\n",
    "# df.hist(figsize=(20,20))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf3a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>saleDate</th>\n",
       "      <th>yearIntroduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1932-09-02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     saleDate  yearIntroduced\n",
       "25 1932-09-02            2014"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ensure proper dtypes\n",
    "df['saleDate'] = pd.to_datetime(df['saleDate'], errors='coerce')\n",
    "df['yearIntroduced'] = pd.to_numeric(df['yearIntroduced'], errors='coerce')\n",
    "\n",
    "mask = (\n",
    "    df['saleDate'].notna() &\n",
    "    df['yearIntroduced'].notna() &\n",
    "    (df['yearIntroduced'] > df['saleDate'].dt.year)\n",
    ")\n",
    "\n",
    "df_bad = df.loc[mask, ['saleDate','yearIntroduced']]\n",
    "df_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316ba45",
   "metadata": {},
   "source": [
    "Target EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"targetPrice\"].hist(bins=100)\n",
    "# plt.show()\n",
    "\n",
    "# df[\"targetPrice\"].describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80801e3a",
   "metadata": {},
   "source": [
    "Cleaned Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb314bad2b547b6b8f7b8d8dcf42fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean = pd.read_csv('../artifacts/clean_data.csv')\n",
    "ProfileReport(clean, title=\"Cleaned Data EDA\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.DataFrame(df[\"model\"].value_counts(normalize=True)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6559daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df[\"make\"].value_counts(normalize=True)[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
